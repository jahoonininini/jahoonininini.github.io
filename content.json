{"pages":[],"posts":[{"title":"NumPy","text":"Numpy Numpy 가 나온 이유는 두개의 리스트를 가지고 계산을 하기 위해서 Numpy 는 일종의 행렬이다. Numpy 는 수치를 계산해준다. np.array() 이 함수를 통해 리스트를 배열로 바꿔준다. Reshape 모양을 바꿔준다. np.reshape 에서 -1 의 의미는 숫자를 자동으로 바꿔준다. NumPy 설치1$ conda install numpy 또는 1$ pip install numpy NumPy를 가져오는 방법NumPy에 액세스하려면 해당 함수가 다음과 같은 파이썬 코드에서 가져옵니다. 1$ import numpy as np 예제 코드 읽기12345678910111213141516171819202122232425262728293031$ import numpy as np$ a = np.arange(15).reshape(3, 5)$ print(a)array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14]])$ a.shape(3, 5)$ a.ndim2$ a.dtype.name'int64'$ a.itemsize8$ a.size15$ type(a)&lt;class 'numpy.ndarray'&gt;$ b = np.array([6, 7, 8])$ print(b)array([6, 7, 8])$ print(type(b))&lt;class 'numpy.ndarray'&gt; 배열 생성1234567891011$ import numpy as np$ a = np.array([2, 3, 4])$ print(a)array([2, 3, 4])$ print(a.dtype)dtype('int64')$ b = np.array([1.2, 3.5, 5.1])$ print(b.dtype)dtype('float64') 2차원 배열에서 3차원 배열로 변환 기능1234$ b = np.array([(1.5, 2, 3), (4, 5, 6)])$ print(b)array([[1.5, 2. , 3. ], [4. , 5. , 6. ]]) 기본 배열을 만드는 방법NumPy 배열을 만들려면 함수를 사용할 수 있다. np.array() 12import numpy as npa = np.array([1, 2, 3]) 1234567891011121314151617181920212223$ np.zeros(2)array([0., 0.])$ np.ones(2)array([1., 1.])$ np.empty(2)array([ 3.14, 42. ])$ np.arange(4)array([0, 1, 2, 3])# 첫 번째 번호, 마지막 번호, 단계 크기$ np.arange(2, 9, 2)array([2, 4, 6, 8])# 지정된 간격이 있는 선형 배열$ np.linspace(0, 10, num=5)arrya([0. , 2.5, 5. , 7.5, 10. ])$ x = np.ones(2, dtype=np.int64)$ print(x)array([1, 1]) 요소 추가, 제거 및 정렬 요소 정렬 - np.sort()123456789101112131415$ arr = np.array([2, 1, 5, 3, 7, 4, 6, 8])$ np.sort(arr)array([1, 2, 3, 4, 5, 6, 7, 8])# np.concatenate()$ np.concatenate((a, b))array([1, 2, 3, 4, 5, 6, 7, 8])$ x = np.array([[1, 2], [3, 4]])$ y = np.array([[5, 6]])$ np.concatenate((x, y), axis=0)array([[1, 2], [3, 4], [5, 6]]) 배열의 모양과 크기 ndarray.ndim - 축 또는 치수 수 ndarray.size - 배열의 총 요소 수 ndarray.shape - 배열의 각 치수에 저장된 요소 수를 나타내는 정수 튜플12345678&gt;&gt;&gt; array_example = np.array([[[0, 1, 2, 3],... [4, 5, 6, 7]],...... [[0, 1, 2, 3],... [4, 5, 6, 7]],...... [[0 ,1 ,2, 3],... [4, 5, 6, 7]]]) 12345678$ array_example.ndim3$ array_example.size24$ array_example.shape(3, 2, 4) 배열 바꾸기 arr.reshape()123456789101112$ a = np.arange(6)$ print(a)[0 1 2 3 4 5]$ b = a.reshape(3, 2)$ print(b)[[0 1] [2 3] [4 5]]$ numpy.reshape(a, newshape=(1, 6), order='C')array([[0, 1, 2, 3, 4, 5]]) newshape 은 원하는 모양의 배열로 만들어 준다. order:C C와 같은 인덱스 순서를 사용하여 요소를 읽고 쓰는 것을 의미 1D 배열을 2D 배열로 변환 np.newaxis배열의 치수가 한 차원씩 증가한다.1D -&gt; 2D, 2D -&gt; 3D np.expand_dims1234567891011$ a = np.array([1, 2, 3, 4, 5, 6])$ print(a.shape)(6,)$ b = np.expand_dims(a, axis=1)$ b.shape(6, 1)$ c = np.expand_dims(a, axis=0)$ c.shape(1, 6) 인덱싱 및 슬라이싱 Python 목록을 분할하는 것과 동일한 방법으로 Numpy 배열을 인덱싱하고 분할할 수 있다. 1$ import numpy as np 1$ data = np.array([1, 2, 3]) 1234567891011$ print(data[1])2$ print(data[0:2])[1 2]$ print(data[1:])[2 3]$ print(data[-2:])[2 3] 1$ a = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]) 1$ print(a[a &lt; 5]) 5 보다 작은 배열의 모든 값을 쉽게 인쇄 할 수 있다. 123$ five_up = (a &gt;= 5)$ print(a[five_up])[ 5 6 7 8 9 10 11 12] 5 보다 크거나 같은 숫자를 선택하고 해당 조건을 사용하여 배열을 인덱싱 할 수도 있다. 123$ divisible_by_2 = a[a%2==0]$ print(divisible_by_2)[ 2 4 6 8 10 12] 2 로 나눌 수 있는 값을 인덱싱할 수도 있다. 123$ c = a[(a &gt; 2) &amp; (a &lt; 11)]$ print(c)[ 3 4 5 6 7 8 9 10] $ five_up = (a &gt; 5) | (a == 5)$ print(five_up)[[False False False False] [ True True True True] [ True True True True]] 1$ 및 | 배열의 값이 특정 조건을 충족하는지 여보를 지정할 수도 있다. np.nonzero()1$ a = np.array([[1 , 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]) 5 미만의 값을 출력할 수 있다. 123$ b = np.nonzero(a &lt; 5)$ print(b)(array([0, 0, 0, 0], dtype=int64), array([0, 1, 2, 3], dtype=int64)) 1234567$ list_of_coordinates = list(zip(b[0], b[1]))$ for coord in list_of_coordinates: print(coord)(0, 0)(0, 1)(0, 2)(0, 3) 12$ print(a[b])[1 2 3 4] 찾고 있는 값이 배열에 존재하지 않으면 반환된 인덱스 배열이 비어 있다. 123$ not_there = np.nonzero(a == 42)$ print(not_there)(array([], dtype=int64), array([], dtype=int64)) 기존 데이터에서 배열을 만드는 방법1$ a = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]) 배열을 슬라이스 할 위치를 지정하여 언제든지 배열의 섹션에서 새 배열을 만들 수 있다. 123$ arr1 = a[3:8]$ print(arr1)[4 5 6 7 8] vsstack 을 사용하여 세로로 쌓을 수 있다. 123456789$ a1 = np.array([[1, 1], [2,2]])$ a2 = np.array([[3,3], [4,4]])$ print(np.vstack((a1, a2)))[[1 1] [2 2] [3 3] [4 4]] 또는 hstack 을 사용해 가로로 쌓을 수 있다. 123$ print(np.hstack((a1, a2)))[[1 1 3 3] [2 2 4 4]] hsplit 을 통해 배열을 작은 배열로 분할 할 수 있다.","link":"/2021/06/23/numpy1/"},{"title":"가상환경","text":"기본 라이브러리 GUI 프로그램 - tinker 데이터분석 - ML, DL 웹 개발 - flask, django 서로 의존하는 라이브러리 버전이 다룰 수 있기 때문에 패키지를 같이 사용하기에는 관리가 어렵다. 대표적 가상환경 pipenv virtualenv conda 가상환경 필요성 tensorflow 1.x 버전과 tensorflow 2.x 버전이 있는데 이 두 개의 버전이 완전히 다르다. 다운그레이드 하기 위해 가상환경이 필요하다. 시각화 정적 시각화 - matplotlib + seaborn 동적 시각화 - plotly 1줄 요약 관리자 실행해서 아나콘다 가상 환경을 만든 후, 새로운 패키지를 설치한다. PyCaret 설치 방법 (Windows 10) 아나콘다 설치 후 환경변수에 추가 한다.(중요하다) 가상환경 설정 새로운 가상환경을 만든다. 명령프롬프트를 관리자로 실행한다. 현재 경로는 아래와 같다1C:\\Users\\1\\Desktop\\pycaret 적절한 경로에 pycaret 폴더를 만들어 cmd 에서 경로에 들어간다. 가상환경을 만든다. 1$ conda create --name yourenvname python=3.8 yourenvname 대신 pycaret 이라고 이름을 지었따. 그 후에, 가상환경에 접속한다.(중요하다!!)1$ conda activate pycaret 마지막으로 pycaret 을 설치합니다.1$ pip install pycaret PyCaret 을 설치하기 위해서 Scikit-Learn, Pandas 등을 사전에 먼저 설치할 필요가 없습니다. 만약 설치가 되어 있다면, 버전 충돌이 발생할 수가 있습니다. 즉, 이 때에는 기존에 설치된 패키지를 삭제 후 재 설치를 해야 합니다. 이러한 번거로움을 겪지 않기 위해, 새로운 가상 환경을 아예 만들어 설치하는 것이 훨씬 간편합니다. 설치 중 에러 발생시 환경변수가 제대로 돼 있는지 확인 Scikit-Learn, Pandas 가 설치 돼 있는지 확인하고 있다면 삭제한다. C++ 이 설치 돼 있느지 확인하고 없다면 설치한다.주피터 노트북 실행 이제 anaconda.navigator 에서 주피터 노트북을 실행해준다. 아나콘다를 관리자로 실행한 후, 가상환경 이름을 찾아서 클릭한다. 처음 작업하는 것이라면 Jupyter Notebook이나 Lab에서 설치를 먼저 해줘야 합니다. Jupyter Lab 또는 jupyter notebook 을 설치 실행합니다. pycaret 가상환경의 jupiter lab 또는 jupyter notebook 에서 코드를 작성해보고 제대로 실행 됐는지 확인한다.123from pycaret.datasets import get_datadataset = get_data('credit')dataset.shape 결론은 가상환경을 잘 써야한다고 한다. 강사님께 배운 툴 google colab kaggle PyCaret","link":"/2021/06/24/virtual_configuration/"},{"title":"파이썬 기본 문법 1","text":"문법 종류자료형 / 숫자형 / 문자형 / 불형 / 리스트형 / 딕셔너리 / 튜플 / 집합형 tip ctrl + / 로 한번에 주석처리 가능 \\n - 줄을 바꿀 때 \\t - 탭 간격을 줄때 ' - 문자열 내에 ‘ ‘ 표시 \\r - 줄바꿈 / 커서를 가장 앞으로 이동 len() 공백까지 포함한 문자열의 길이를 구하는 함수 인덱싱 할때는 [] 를 사용한다. 0 이 첫번째 문자열을 의미한다. % - 대입 d - 정수 s - 문자열의 변수명 print(“오늘은 온도가 %d도입니다.” % 20) print(“오늘의 수업은 %s 기초 입니다.” % “파이썬”) print(“오늘은 {0}도이며 수업은 {1}입니다.”format(20, “python”)) append = 추가, sort = 정렬, reverse = 반전, pop - 리스트의 마지막 str 삭제 count - 자료형의 str 갯수 출력 튜플 - 튜플은 리스트와 달리 자료형이 다른 것들도 담을 수 있다. 1st = (1, 2, &quot;a&quot;, &quot;b&quot;) 튜플에서는 일반적이 방식에서는 한 번 들어간 값을 변경, 수정이 힘들다. 딕셔너리 {key1:Value1, key2:Value2, key3:Value3} 123456a = {1: &quot;hi&quot;}b = {&quot;a&quot;: [1,2,3]}a[2] = &quot;how are you&quot;print(a)del a[2]print(a) 교집합 - &amp;, 합집합 - |,or(중복 허용 안함), 차집합 - - set 을 통해 집합을 만들 수 있다. 1s1 = set([1,2,3,1,4])","link":"/2021/06/23/0621before/BaseGrammer/"},{"title":"제어문, 조건문, 반복문","text":"제어문, 조건문, 반복문 실습123456789101112131415coffee = 10while True: money = int(input(&quot;돈을 넣어 주세요 : &quot;)) if money == 300: print(&quot;커피를 줍니다.&quot;) coffee = coffee - 1 elif money &gt; 300: print(&quot;거스름 돈 %d 를 주고 커피를 줍니다.&quot; % (money - 300)) coffee = coffee - 1 else: print(&quot;돈을 다시 돌려주고 커피를 주지 않습니다.&quot;) print(&quot;남은 커피의 양은 %d 개 입니다.&quot; % coffee) if coffee == 0: print(&quot;커피가 다 떨어졌습니다. 판매를 중지 합니다&quot;) break","link":"/2021/06/23/0621before/BaseGrammer_2/"},{"title":"기본 사칙연산, 슬라이싱","text":"12345# 이두환 평균 점수# 국어 80, 영어 100, 수학 75duhwan = [80, 100, 75]average = (duhwan[0] + duhwan[1] + duhwan[2]) / len(duhwan)print(average) 12345678# 17이 짝수? 홀수?a = 17if (a % 2 == 0): print(&quot;짝수&quot;)else: print(&quot;홀수&quot;)``` 홍길동 876504-1234567생년월일을 추출하여 결과값으로# 홍길동님의 생일은hong = ‘8765041234567’print(hong[:2],”년”,hong[2:4],”월”,hong[4:6],”일”) if(int(hong[6]) % 2 == 1): print(“남자”)else: print(“여자”)```","link":"/2021/06/23/0621before/BaseGrammer_Practice/"},{"title":"웹 크롤링, 웹 스크래핑","text":"라이브러리 설치12pip install beautifulsouppip install lxml import1234from os import nameimport requestsimport refrom bs4 import BeautifulSoup 네이버 웹툰12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576url = &quot;https://comic.naver.com/webtoon/weekday.nhn&quot;res = requests.get(url)res.raise_for_status()soup = BeautifulSoup(res.text, &quot;lxml&quot;)print(soup.title)print(soup.title.get_text())print(soup.a[&quot;href&quot;])print(soup.a.aatrs)print(soup.find(&quot;a&quot;, attra={&quot;class&quot;:&quot;Nbtn_upload&quot;}))print(soup.find(attra={&quot;class&quot;:&quot;Nbtn_upload&quot;}))print(soup.find(&quot;li&quot;, attrs={&quot;class&quot;: &quot;rank01&quot;}))rank1 = soup.find(&quot;li&quot;, attrs={&quot;class&quot;: &quot;rank01&quot;})print(rank1.a)print(rank1.a.get_text())print(rank1.next_sibling)print(rank1.next_sibling.next_sibling)# 호랑이 형님 - 각 화 만화제목 + 링크 가져오기url = &quot;https://comic.naver.com/webtoon/list.nhn?titleId=650305&quot;res = requests.get(url)res.raise_for_status()soup = BeautifulSoup(res.text, &quot;lxml&quot;)cartoons = soup.find_all(&quot;td&quot;, attrs={&quot;class&quot;:&quot;title&quot;})title = cartoons[0].a.get_text()link = cartoons[0].a[&quot;href&quot;]print(title, link)for cartoon in cartoons: title = cartoon.a.get_text() link = &quot;https://comic.naver.com&quot; + cartoon.a[&quot;href&quot;] print(title, link) total_rates = 0cartoons = soup.find_all(&quot;div&quot;, attrs={&quot;class&quot;:&quot;rating_type&quot;})for cartoon in cartoons: rate = cartoon.find(&quot;strong&quot;).get_text() print(rate) total_rates += round(float(rate), 2)print(&quot;전체 점수 : &quot;, round(total_rates), 2)print(&quot;평균 점수 : &quot;, round(total_rates / len(cartoons), 2))import requestsfrom bs4 import BeautifulSoupres = requests.get( &quot;https://search.daum.net/search?w=tot&amp;q=2020%EB%85%84%EC%98%81%ED%99%94%EC%88%9C%EC%9C%84&amp;DA=MOR&amp;rtmaxcoll=MOR&quot;)res.raise_for_status()soup = BeautifulSoup(res.text, &quot;lxml&quot;)images = soup.find_all(&quot;img&quot;, attrs={&quot;class&quot;: &quot;thumb_img&quot;})# 첫 번째 실행 후 for문 작성 시 idx, enumerate 없이(두 번째 실행 이후)# 마지막 실습for idx, image in enumerate(images): # print(image[&quot;src&quot;]) # 한 번 실행 후 주석 처리 image_url = image[&quot;src&quot;] if image_url.startswith(&quot;//&quot;): image_url = &quot;https:&quot; + image_url print(image_url) # 두 번째 실행 image_res = requests.get(image_url) image_res.raise_for_status() with open(&quot;movie{0}.jpg&quot;.format(idx+1), &quot;wb&quot;) as f: f.write(image_res.content) # 세 번째 실행 if idx &gt;= 4: # 상위 5개 이미지까지만 다운로드 break","link":"/2021/06/23/0621before/beso4/"},{"title":"class quiz","text":"퀴즈 주어진 코드를 활용하여 부동산 프로그램을 작성하시오.(출력 예제) 총 3 곳의 매물이 있습니다. 동구 아파트 매매 5억 2020년 달성군 오피스텔 전세 3억 2021년 북구 빌라 월세 500/30 2019 Codeclass House: # 매물을 초기화 def __init__(self, location, house_type, deal_type, price, complection_year): self.location = location self.house_type = house_type self.deal_type = deal_type self.price = price self.complection_year = complection_year # 매물 정보 표시 def show_detail(self): print(self.location, self.house_type, self.deal_type, self.price, self.complection_year) a = House(&quot;동구&quot;, &quot;아파트&quot;, &quot;매매&quot;, &quot;5억&quot;, &quot;2020년&quot;) a.show_detail() b = House(&quot;달성군&quot;, &quot;오피스텔&quot;, &quot;전세&quot;, &quot;3억&quot;, &quot;2021년&quot;) b.show_detail() c = House(&quot;북구&quot;, &quot;빌라&quot;, &quot;월세&quot;, &quot;500/30&quot;, &quot;2019&quot;) c.show_detail() houses = [] house1 = House(&quot;동구&quot;, &quot;아파트&quot;, &quot;매매&quot;, &quot;5억&quot;, &quot;2020년&quot;) house2 = House(&quot;달성군&quot;, &quot;오피스텔&quot;, &quot;전세&quot;, &quot;3억&quot;, &quot;2021년&quot;) house3 = House(&quot;북구&quot;, &quot;빌라&quot;, &quot;월세&quot;, &quot;500/30&quot;, &quot;2019&quot;) houses.append(house1) houses.append(house2) houses.append(house3) print(&quot;총 {0} 곳의 매물이 있습니다.&quot;.format(len(houses))) for house in houses: house.show_detail()","link":"/2021/06/23/0621before/class-quiz/"},{"title":"pandas","text":"Pandas1import pandas as pd pandas 자료구조 DataFrame(2차원배열) / Series(1차원배열) Series12345s1 = pd.Series([3, 6, 5, 4, 7])print(s1)print(s1.values)print(s1.index)print(s1.dtypes) 1234567s2 = pd.Series([3, 6, 5, 4, 7], index=[&quot;p&quot;, &quot;q&quot;, &quot;r&quot;, &quot;s&quot;, &quot;t&quot;])print(s2)print(s2[&quot;p&quot;])print(s2[0])print(s2.p)print(s2[:2])print(s2.reindex([&quot;a&quot;, &quot;r&quot;, &quot;s&quot;, &quot;u&quot;, &quot;t&quot;])) 12345s3 = pd.Series({&quot;math&quot;:95, &quot;lang&quot;:90, &quot;code&quot;:95})print(s3)s3.name = &quot;Scores&quot;s3.index.name = &quot;Subject&quot;print(s3) DataFrame123456789101112x = pd.DataFrame([[1, 2, 3], [4, 5, 6], [7, 8, 9]])print(x)print(x.values)data = {&quot;subject&quot;: [&quot;math&quot;, &quot;comp&quot;, &quot;phys&quot;, &quot;music&quot;], &quot;score&quot;: [90, 80, 90, 100], &quot;students&quot;: [94, 85, 96, 90]}print(pd.DataFrame(data))y = pd.DataFrame(data)print(y.dtypes)print(len(y))print(y.shape)print(y.shape[0])print(y.shape[1])","link":"/2021/06/23/0621before/data_ana/"},{"title":"selenium","text":"selenium 3.141.0다음 로그인 (Webdriver를 이용)12345678910111213141516171819from selenium import webdriverbrowser = webdriver.Chrome()browser.maximize_window()url = &quot;https://www.daum.net/&quot;browser.get(url)browser.find_element_by_class_name(&quot;link_login&quot;).click()id = browser.find_element_by_id(&quot;id&quot;)id.click()id.send_keys(&quot;identify&quot;)pw = browser.find_element_by_id(&quot;inputPwd&quot;)pw.click()pw.send_keys(&quot;1234&quot;)browser.find_element_by_class_name(&quot;btn_comm&quot;).click()","link":"/2021/06/23/0621before/daum_login/"},{"title":"exception","text":"동네에 맛있는 치킨집이 있다. 대기 손님을 위해 자동 주문 시스템을 제작하였다. 시스템 코드를 확인하고 적절하게 예외처리 구문을 넣어보자. 조건 1 1 보다 적거나 숫자가 아닌 입력값이 들어올 때는 ValueError 로 처리 메시지 “잘못된 값을 입력하였습니다.” 조건 2 총 치킨량이 10마리로 한정 치킨 소진 시 사용자 정의 에러[SoldOutError]를 발생시키고 프로그램 종료 메시지 “재고가 소진되어 더 이상 주문을 받지 않습니다.” 코드1234567891011121314151617181920212223242526class SoldOutError(Exception): passchicken = 10 # 남은 치킨 수waiting = 1 # 매장 안에는 만석, 대기번호는 1번부터 시작while(True): try: print(&quot;[남은 치킨 : {0}]&quot;.format(chicken)) order = int(input(&quot;치킨 몇 마리 주문하시겠습니까?&quot;)) if order &gt; chicken: # 남은 치킨보다 주문량이 많을 때 print(&quot;재료가 부족합니다.&quot;) elif order &lt;= 0: raise ValueError else: print(&quot;[대기번호 {0}] {1} 마리 주문이 완료되었습니다.&quot;.format(waiting, order)) waiting += 1 # 대기번호 증가 chicken -= order # 주문 수 만큼 남은 치킨 감소 if chicken == 0: raise SoldOutError except ValueError: print(&quot;잘못된 값을 입력하였습니다.&quot;) except SoldOutError: # 사용자 정의 예외처리 print(&quot;재고가 소진되어 더 이상 주문을 받지 않습니다.&quot;) break","link":"/2021/06/23/0621before/exception/"},{"title":"구글 영화 정보 가져오기","text":"구글 무비 정보 가져오기1234567891011121314import requestsfrom bs4 import BeautifulSoupurl = &quot;https://play.google.com/store/movies/top&quot;res = requests.get(url)res.raise_for_status()soup = BeautifulSoup(res.text, &quot;lxml&quot;)movies = soup.find_all(&quot;div&quot;, attrs={&quot;class&quot;:&quot;WsMG1c nnK0zc&quot;})print(len(movies))with open(&quot;movie.html&quot;, &quot;w&quot;, encoding=&quot;utf8&quot;) as f: f.write(res.text) f.write(soup.prettify()) # html 문서를 조금 예쁘게 출력","link":"/2021/06/23/0621before/google-movie/"},{"title":"lotto","text":"12345678910111213141516171819202122232425262728import requestsurl = &quot;http://www.dhlottery.co.kr/common.do?method=getLottoNumber&amp;drwNo=+&quot;res = requests.get(url)print(res.json())# {&quot;totSellamnt&quot;:95640447000,&quot;returnValue&quot;:&quot;success&quot;,&quot;drwNoDate&quot;:&quot;2021-06-05&quot;,&quot;firstWinamnt&quot;:2411303513,&quot;drwtNo6&quot;:37,&quot;drwtNo4&quot;:29,&quot;firstPrzwnerCo&quot;:10, &quot;drwtNo5&quot;:34,&quot;bnusNo&quot;:36,&quot;firstAccumamnt&quot;:24113035130,&quot;drwNo&quot;:966,&quot;drwtNo2&quot;:21,&quot;drwtNo3&quot;:25,&quot;drwtNo1&quot;:1}def inputRoundNumber(): roundNumber = input(&quot;당첨번호 확인할 회차를 입력해주세요 : &quot;) return roundNumberdef getJsonFromUrl(url): return requests.get(url)def existLottoData(json, roundNumber): if(json[&quot;returnValue&quot;] == &quot;success&quot;): print(json) return True else: print(&quot;존재하지 않는 회차 번호입니다.({0})&quot;.format(roundNumber)) return False def writeJsonToFile(file, jsonData): fout = open(file, &quot;w&quot;) fout.write(str(jsonData)) fout.close() 실제 함수들을 활용1234567891011roundNumber = - 1while int(roundNumber) != 0: lottoURL = &quot;http://www.dhlottery.co.kr/common.do?method=getLottoNumber&amp;drwNo=+&quot; roundNumber = inputRoundNumber() url = lottoURL + roundNumber res = getJsonFromUrl(url) print(res.json()) exist = existLottoData(res.json(), roundNumber) if(exist): writeJsonToFile(&quot;output.txt&quot;, res.json())","link":"/2021/06/23/0621before/lotto/"},{"title":"Module","text":"Module (모듈)1234567891011121314import theater_moduletheater_module.price(3)theater_module.price_mornig(4)theater_module.price_soldier(5)import theater_module as mv # 모듈 이름 변경mv.price(3)mv.price_mornig(4)from theater_module import *price(3)price_mornig(4)price_soldier(5) 12from theater_module import price_soldier as priceprice(5) package(패키지)123import travel.thailandtrip_to = travel.thailand.ThailandPackage()trip_to.detail() 123from travel import vietnamtrip_to = vietnam.VietnamPackage()trip_to.detail() 1from travel import * 모듈 위치1234import inspectimport randomprint(inspect.getfile(random))print(inspect.getabsfile(vietnam)) 내장 함수 input - 사용자 입력을 받는 함수123language = input(&quot;어떤 언어를 좋아하나요?&quot;)print(&quot;{0}은 아주 좋은 언어입니다.&quot;.format(language))print(dir()) 12345678910import pickleprint(dir())print(dir(pickle))print(dir(random))lst = [1, 2, 3, 4, 5]print(dir(lst))name = &quot;hooni&quot;print(dir(name))","link":"/2021/06/23/0621before/module_package/"},{"title":"네이버 air","text":"네이버 Air 자동 표 예매 과정12345678910111213141516171819202122232425262728293031323334353637from selenium import webdriverfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECbrowser = webdriver.Chrome()browser.maximize_window() # 창 최대화url = &quot;https://flight.naver.com/flights/&quot;browser.get(url) # URL 로 이동하기 위한 명령어# 가는날 선택(일정 선택)browser.find_element_by_link_text(&quot;가는날 선택&quot;).click()# 실제 요일 선택# 이번 달 5일 7일 선택browser.find_elements_by_link_text(&quot;5&quot;)[0].click()browser.find_elements_by_link_text(&quot;7&quot;)[0].click()# 목적지 설정 및 항공권 검색 버튼 클릭# browser.find_element_by_xpath(&quot;//*[@id='recommendationList']/ul/li[1]/div/span&quot;).click()browser.find_element_by_xpath(&quot;//*[@id='recommendationList']/ul/li[1]&quot;).click()browser.find_element_by_link_text(&quot;항공권 검색&quot;).click()# 검색 결과 출력# elem = browser.find_element_by_xpath(&quot;//*[@id='recommendationList']/ul/li[1]/div/span&quot;)# print(elem.text)# 검색에 따른 예외 처리try: elem = WebDriverWait(browser, 10).until(EC.presence_of_element_located((By.XPATH, &quot;//*[@id='content']/div[2]/div/div[4]/ul/li[1]&quot;))) # 성공했을 때 동작 수행 print(elem.text) # 첫 번째 결과 출력finally: browser.quit() # 브라우저 종료","link":"/2021/06/23/0621before/naver-air/"},{"title":"네이버 IT 뉴스 크롤링","text":"네이버 IT 뉴스 크롤링1234567891011121314151617181920212223242526import requestsfrom bs4 import BeautifulSoupprint(&quot;[IT관련 뉴스]&quot;)url = &quot;https://news.naver.com/main/main.nhn?mode=LSD&amp;mid=shm&amp;sid1=105&quot;headers = { &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36&quot;}res = requests.get(url, headers=headers)res.raise_for_status()soup = BeautifulSoup(res.text, &quot;lxml&quot;)news_list = soup.find(&quot;div&quot;, attrs={&quot;class&quot;: &quot;cluster_body&quot;}).find_all(&quot;li&quot;, limit=3)for index, news in enumerate(news_list): a_idx = 0 img = news.find(&quot;img&quot;) if img: a_idx = 1 # a 태그가 있으면 1번째 a 태그의 정보를 가져옴 title = news.find_all(&quot;a&quot;)[a_idx].get_text().strip() link = news.find_all(&quot;a&quot;)[a_idx][&quot;href&quot;] print(&quot;{0}.&quot; &quot;{1}&quot;.format(index+1, title)) print(&quot; ( 링크 : {0} )&quot;.format(link))print()","link":"/2021/06/23/0621before/naver_IT/"},{"title":"나만의 비서","text":"프로젝트 : 웹 스크래핑을 통해 나만의 비서를 만들어보자. [조 건] 네이버에서 오늘 대구의 날씨를 가져온다. 네이버에서 헤드라인 뉴스 3건을 가져온다. IT 뉴스 3건을 가져온다 오늘의 영어 회화 지문을 가져온다.(해커스 어학원) [출력 예시]코딩은 같은 내용이라도 처음에는 반복해서 적어본다.그러면 언젠간 머리가 아닌 손으로.여러 가지 예제를 직접 해보는 것이 중요하다.파이썬 기초 : w3school, python.org, 위키독스(점프투파이썬)import requestsfrom bs4 import BeautifulSoupimport re def create_soup(): headers = { “User-Agent”: “Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36”} res = requests.get(url, headers=headers) res.raise_for_status() soup = BeautifulSoup(res.text, “lxml”) return soup def scrape_weather(): print(“[오늘의 날씨]”) url = “https://search.naver.com/search.naver?where=nexearch&amp;sm=top_hty&amp;fbm=1&amp;ie=utf8&amp;query=%EB%8C%80%EA%B5%AC+%EB%82%A0%EC%94%A8&quot; res = requests.get(url) res.raise_for_status() soup = BeautifulSoup(res.text, “lxml”) # 맑음, 어제보다 OO도 높아요 cast = soup.find(“p”, attrs={“class”: “cast_txt”}).get_text() # 현재 OO도 (최저 OO도 / 최고 OO도) curr_temp = soup.find( “p”, attrs={“class”: “info_temperature”}).get_text().replace(“도씨”, “”) min_temp = soup.find(“span”, attrs={“class”: “min”}).get_text() # 최저 온도 max_temp = soup.find(“span”, attrs={“class”: “max”}).get_text() # 최고 온도 # 오전 강수확률 OO% / 오후 강수확률 OO% morning_rain_rate = soup.find( “span”, attrs={“class”: “point_time morning”}).get_text().strip() afternoon_rain_rate = soup.find( “span”, attrs={“class”: “point_time afternoon”}).get_text().strip() # 미세먼지 ( ) 좋음 # 초미세먼지 ( ) 보통 dust = soup.find(“dl”, attrs={“class”: “indicator”}) pm = dust.find(“dd”, attrs={“class”: “lv2”}).get_text() print(cast) print(&quot;현재 {0} (최저 {1} / 최고 {2})&quot;.format(curr_temp, min_temp, max_temp)) print(&quot;오전 {0} / 오후 {1}&quot;.format(morning_rain_rate, afternoon_rain_rate)) print() print(&quot;미세먼지 {0}&quot;.format(pm)) print() [헤드라인 뉴스]1. 뉴스 내용……( 링크 : https://…….)def scrape_headline_news():print(“[헤드라인 뉴스]”)url = “https://news.naver.com&quot;headers = {“User-Agent”: “Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36”}res = requests.get(url, headers=headers)res.raise_for_status()soup = BeautifulSoup(res.text, “lxml”)# create_soup()news_list = soup.find(“ul”, attrs={“class”: “hdline_article_list”}).find_all(“li”, limit=3)for index, news in enumerate(news_list):title = news.find(“a”).get_text().strip()link = url + news.find(“a”)[“href”]print(“{0}.” “{1}”.format(index+1, title))print(“ ( 링크 : {0} )”.format(link))print()[IT관련 뉴스]1. IT 뉴스……(링크 : https://……)def scrape_it_news(): print(“[IT관련 뉴스]”) url = “https://news.naver.com/main/list.nhn?mode=LS2D&amp;mid=shm&amp;sid1=105&amp;sid2=230&quot; headers = { “User-Agent”: “Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36”} res = requests.get(url, headers=headers) res.raise_for_status() soup = BeautifulSoup(res.text, “lxml”) news_list = soup.find( &quot;ul&quot;, attrs={&quot;class&quot;: &quot;type06_headline&quot;}).find_all(&quot;li&quot;, limit=3) for index, news in enumerate(news_list): a_idx = 0 img = news.find(&quot;img&quot;) if img: a_idx = 1 # a 태그가 있으면 1번째 a 태그의 정보를 가져옴 title = news.find_all(&quot;a&quot;)[a_idx].get_text().strip() link = news.find_all(&quot;a&quot;)[a_idx][&quot;href&quot;] print(&quot;{0}.&quot; &quot;{1}&quot;.format(index+1, title)) print(&quot; ( 링크 : {0} )&quot;.format(link)) print() [오늘의 영어 회화](영어 지문)kim : How are you?hoon : Fine!(한글 지문)kim : 어떠니?hoon : 좋아.def scrape_english():print(“[오늘의 영어 회화]”)url = “https://www.hackers.co.kr/?c=s_eng/eng_contents/I_others_english&amp;keywd=haceng_submain_lnb_eng_I_others_english&amp;logger_kw=haceng_submain_lnb_eng_I_others_english&quot;res = requests.get(url)res.raise_for_status()soup = BeautifulSoup(res.text, “lxml”)print(“(영어 지문)”)sentences = soup.find_all(“div”, attrs={“id”: re.compile(“^conv_kor_t”)})for sentence in sentences[len(sentences)//2:]:print(sentence.get_text().strip())print()print(“(한글 지문)”)for sentence in sentences[:len(sentences)//2]:print(sentence.get_text().strip())print()if name == “main“:scrape_weather() # 오늘 날씨 정보 가져오기scrape_headline_news() # 헤드라인 뉴스 가져오기scrape_it_news()scrape_english()","link":"/2021/06/23/0621before/project/"},{"title":"selenium","text":"selenium 설치1pip install selenium 12345from selenium.webdriver.common.keys import Keysfrom selenium import webdriverbrowser = webdriver.Chrome(&quot;./chromedriver.exe&quot;)browser.get(&quot;http://naver.com&quot;) 12345678910elem = browser.find_element_by_class_name(&quot;link_login&quot;)elem.click()browser.backbrowser.forward()elem = browser.find_element_by_id(&quot;query&quot;) elemfrom selenium.webdriver.common.keys import Keyselem.send_keys(&quot;영화순위&quot;) elem.send_keys(&quot;파이썬&quot;)elem.send_keys(Keys.ENTER) 1234567# daum.net 으로 바꿔서elem = browser.find_element_by_tag_name(&quot;a&quot;)for e in elem: e.get_attribute(&quot;href&quot;) browser.get(&quot;http://daum.net&quot;)browser.close()browser.quit()","link":"/2021/06/23/0621before/selenium1/"},{"title":"theater","text":"극장 요금 기능이 있는 모듈 일반 가격 12def price(people): print(&quot;{0}명 가격은 {1}원 입니다.&quot;.format(people, people * 10000)) 조조 할인 가격 1234def price_mornig(people): print(&quot;{0}명 가격은 {1}원 입니다.&quot;.format(people, people * 6000))``` - 군인 할인 가격 def price_soldier(people): print(“{0}명 가격은 {1}원 입니다.”.format(people, people * 4000))```","link":"/2021/06/22/0621before/theater_module/"},{"title":"how to google colab file to myblog","text":"google colabgoogle colab 으로 코드를 작성한다.작성한 코드를 ipynb 확장자로 저장한다. anacondaanaconda 에서 JupyterLab lunch 한다. JupyterLabipynb 확장자 파일을 실행한 후 md 확장자로 저장한다. VsCodeVsCode 에 md 확장자 파일은 올려 블로그에 push 한다.","link":"/2021/06/22/0622/google_colab_to_myblog/"},{"title":"pandas 로 csv 활용","text":"1234567import pandas as pddata = pd.read_csv(&quot;기상청_관광코스별 관광지 상세날씨 조회 지점 정보_20200110.csv&quot;)# print(data)selectdata = data[[&quot;1&quot;, &quot;2&quot;, &quot;3&quot;]]# print(selectdata)selectdata.to_csv(&quot;./test.csv&quot;)","link":"/2021/06/23/0621before/tour/"},{"title":"webtoon best","text":"123456789101112131415161718192021222324from re import Aimport requestsfrom bs4 import BeautifulSoupprint(&quot;[오늘의 베스트 웹툰]&quot;)url = &quot;https://comic.naver.com/genre/bestChallenge.nhn&quot;headers = {&quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36&quot;}res = requests.get(url, headers=headers)res.raise_for_status()soup = BeautifulSoup(res.text, &quot;lxml&quot;)today_webtoons= soup.find(&quot;ul&quot;, attrs={&quot;class&quot;: &quot;mainTodayList&quot;})a = 0while today_webtoons: title = today_webtoons.find_all(&quot;h4&quot;)[a].get_text().strip() rate = today_webtoons.find_all(&quot;strong&quot;)[a].get_text() print(&quot;{0}&quot;.format(title)) print(&quot;평점 : {0}&quot;.format(rate)) a += 1 if a == 3: break","link":"/2021/06/22/0621before/webtoon_best/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2021/06/22/0622/hello-world/"},{"title":"how_to_github, git","text":"AI 수업에서 처음배운 git 사용 방법과 github 와의 연동 그리고 기타 명령어에 대해서 정리한다. gitgit 설치https://git-scm.com/downloads 에서 git 을 먼저 설치한다. githubgithub 에서 새로운 저장소를 만들어 준다. gitgit Bash 를 실행해준다. 12$ git init$ git clone + 저장소 경로 계정 로그인12$ git config --global user.name &quot;name&quot;$ git config --global user.email &quot;email&quot; git 을 통해 github 에 커밋123git add .git commit -m &quot;커밋 메시지&quot;git push","link":"/2021/06/22/0622/how_to_git/"},{"title":"How to makes hexo blog","text":"개요 간단하게 Hexo 블로그를 만들어 본다. 필수 파일 설치 1단계: nodejs.org 다운로드 1$ node -v 2단계: git-scm.com 다운로드1$ git --version 3단계: hexo 설치 hexo는 npm을 통해서 설치가 가능하다.1$ npm install -g hexo-cli 블로그 만들기12345$ hexo init myblog$ cd myblog$ npm install$ npm install hexo-server --save$ npm install hexo-deployer-git --save 깃허브에 배포하기123$ hexo generate$ hexo server # localhost:4000 에서 접속을 확인$ hexo deploy","link":"/2021/06/22/0622/how_to_mk_hexo_blog/"},{"title":"temp","text":"welcome to [temp]! Quick StartCreate a new post1$ &quot;upload image&quot; 1. 스위스 사진 1 스위스 사진 2","link":"/2021/06/22/0622/temp/"},{"title":"temp1","text":"개요 본 수업은 – 수업 1 수업 1은 …. 11+1 데이터 수집 데이터 수집은…. 12date = 1import date 2","link":"/2021/06/22/0622/temp1/"}],"tags":[{"name":"제어문, 조건문, 반복문","slug":"제어문-조건문-반복문","link":"/tags/%EC%A0%9C%EC%96%B4%EB%AC%B8-%EC%A1%B0%EA%B1%B4%EB%AC%B8-%EB%B0%98%EB%B3%B5%EB%AC%B8/"},{"name":"class quiz","slug":"class-quiz","link":"/tags/class-quiz/"},{"name":"pandas","slug":"pandas","link":"/tags/pandas/"},{"name":"selenium","slug":"selenium","link":"/tags/selenium/"},{"name":"파이썬 기본 문법 1","slug":"파이썬-기본-문법-1","link":"/tags/%ED%8C%8C%EC%9D%B4%EC%8D%AC-%EA%B8%B0%EB%B3%B8-%EB%AC%B8%EB%B2%95-1/"},{"name":"기본 사칙연산, 슬라이싱","slug":"기본-사칙연산-슬라이싱","link":"/tags/%EA%B8%B0%EB%B3%B8-%EC%82%AC%EC%B9%99%EC%97%B0%EC%82%B0-%EC%8A%AC%EB%9D%BC%EC%9D%B4%EC%8B%B1/"},{"name":"myblog","slug":"myblog","link":"/tags/myblog/"},{"name":"encoding py to md","slug":"encoding-py-to-md","link":"/tags/encoding-py-to-md/"},{"name":"NumPy","slug":"NumPy","link":"/tags/NumPy/"},{"name":"except","slug":"except","link":"/tags/except/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"lotto","slug":"lotto","link":"/tags/lotto/"},{"name":"Module","slug":"Module","link":"/tags/Module/"},{"name":"scraping","slug":"scraping","link":"/tags/scraping/"},{"name":"가상환경","slug":"가상환경","link":"/tags/%EA%B0%80%EC%83%81%ED%99%98%EA%B2%BD/"},{"name":"theater","slug":"theater","link":"/tags/theater/"}],"categories":[]}